{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset\n",
    "Can choose between 'medium' dataset size for code testing, 'large' for larger dataset, or 'huge' for full dataset (takes a long time to run)\n",
    "\n",
    "Returns non long tail CSV and long tail CSV from selected datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 20)\n",
      "(        user_id  item_id  click  follow_x  like_x  share_x video_category  \\\n",
      "5             1      311      1         0       0        0              0   \n",
      "98            1     1555      0         0       0        0              1   \n",
      "99            1      976      1         0       0        0              0   \n",
      "102           1     1540      0         0       0        0              1   \n",
      "107           1     1601      0         0       0        0              0   \n",
      "...         ...      ...    ...       ...     ...      ...            ...   \n",
      "512413     3766      242      1         0       0        0              1   \n",
      "512415     3766     2072      0         0       0        0              1   \n",
      "512424     3766      113      1         0       0        0              1   \n",
      "512433     3766     1413      1         0       0        0              1   \n",
      "512437     3766     4467      1         0       0        0              1   \n",
      "\n",
      "        watching_times_x  gender  age  hist_1  hist_2  hist_3  hist_4  hist_5  \\\n",
      "5                      1       1    4       2       3   80936     781  111774   \n",
      "98                     0       1    4       2       3   80936     781  111774   \n",
      "99                     1       1    4       2       3   80936     781  111774   \n",
      "102                    1       1    4       2       3   80936     781  111774   \n",
      "107                    0       1    4       2       3   80936     781  111774   \n",
      "...                  ...     ...  ...     ...     ...     ...     ...     ...   \n",
      "512413                 1       1    4    1834   27007     832    6461   27010   \n",
      "512415                 0       1    4    1834   27007     832    6461   27010   \n",
      "512424                 2       1    4    1834   27007     832    6461   27010   \n",
      "512433                 1       1    4    1834   27007     832    6461   27010   \n",
      "512437                 1       1    4    1834   27007     832    6461   27010   \n",
      "\n",
      "        hist_6  hist_7  hist_8  hist_9  hist_10  \n",
      "5         1230   26403     991    2362     1202  \n",
      "98        1230   26403     991    2362     1202  \n",
      "99        1230   26403     991    2362     1202  \n",
      "102       1230   26403     991    2362     1202  \n",
      "107       1230   26403     991    2362     1202  \n",
      "...        ...     ...     ...     ...      ...  \n",
      "512413    1123     772    6326   16571      784  \n",
      "512415    1123     772    6326   16571      784  \n",
      "512424    1123     772    6326   16571      784  \n",
      "512433    1123     772    6326   16571      784  \n",
      "512437    1123     772    6326   16571      784  \n",
      "\n",
      "[37251 rows x 20 columns],         user_id  item_id  click  follow  like  share video_category  \\\n",
      "0             1        4      0       0     0      0              1   \n",
      "1             1     1201      1       0     0      0              1   \n",
      "2             1   250502      1       0     0      0              1   \n",
      "3             1    50885      1       0     0      0              1   \n",
      "4             1    16934      1       0     0      0              0   \n",
      "...         ...      ...    ...     ...   ...    ...            ...   \n",
      "499994     3766     5832      0       0     0      0              1   \n",
      "499996     3766   400807      0       0     0      0              1   \n",
      "499997     3766    22324      1       0     0      0              1   \n",
      "499998     3766     2488      0       0     0      0              1   \n",
      "499999     3766    99791      0       0     0      0              0   \n",
      "\n",
      "        watching_times  gender  age  hist_1  hist_2  hist_3  hist_4  hist_5  \\\n",
      "0                    0       1    4       2       3   80936     781  111774   \n",
      "1                    1       1    4       2       3   80936     781  111774   \n",
      "2                    1       1    4       2       3   80936     781  111774   \n",
      "3                    1       1    4       2       3   80936     781  111774   \n",
      "4                    1       1    4       2       3   80936     781  111774   \n",
      "...                ...     ...  ...     ...     ...     ...     ...     ...   \n",
      "499994               1       1    4    1834   27007     832    6461   27010   \n",
      "499996               1       1    4    1834   27007     832    6461   27010   \n",
      "499997               2       1    4    1834   27007     832    6461   27010   \n",
      "499998               0       1    4    1834   27007     832    6461   27010   \n",
      "499999               0       1    4    1834   27007     832    6461   27010   \n",
      "\n",
      "        hist_6  hist_7  hist_8  hist_9  hist_10  \n",
      "0         1230   26403     991    2362     1202  \n",
      "1         1230   26403     991    2362     1202  \n",
      "2         1230   26403     991    2362     1202  \n",
      "3         1230   26403     991    2362     1202  \n",
      "4         1230   26403     991    2362     1202  \n",
      "...        ...     ...     ...     ...      ...  \n",
      "499994    1123     772    6326   16571      784  \n",
      "499996    1123     772    6326   16571      784  \n",
      "499997    1123     772    6326   16571      784  \n",
      "499998    1123     772    6326   16571      784  \n",
      "499999    1123     772    6326   16571      784  \n",
      "\n",
      "[462749 rows x 20 columns])\n"
     ]
    }
   ],
   "source": [
    "def get_long_tail(tup):\n",
    "    csv, rows = tup\n",
    "    df = pd.read_csv(csv, nrows=rows)\n",
    "    print(df.shape)\n",
    "    value_counts = df['item_id'].value_counts()\n",
    "    smallest_100 = value_counts[value_counts < 100]\n",
    "    smallest_100_tolist = smallest_100.index.tolist()\n",
    "    test = df[df['item_id'].isin(smallest_100_tolist)]\n",
    "\n",
    "    train = pd.merge(df, test, on=[\"user_id\", \"item_id\", \"click\", \"video_category\", \"gender\", \"age\", \"hist_1\", \"hist_2\",\n",
    "                       \"hist_3\", \"hist_4\", \"hist_5\", \"hist_6\", \"hist_7\", \"hist_8\", \"hist_9\", \"hist_10\"], how='outer', indicator=True)\n",
    "    #train = pd.merge(df, test, how='outer', indicator=True)\n",
    "    train = train.loc[train['_merge'] == 'left_only']\n",
    "    train.drop('_merge', axis=1, inplace=True)\n",
    "    return train.dropna(axis=1, how='all'), test\n",
    "\n",
    "\n",
    "ds = 120000000\n",
    "original = 'ctr_data_1M.csv'\n",
    "\n",
    "small = ('file_name.csv', 50000)\n",
    "med = (original, 500000)\n",
    "large = (original, 1200000)\n",
    "huge = (original, ds)\n",
    "\n",
    "# Select dataset here\n",
    "df = get_long_tail(med)\n",
    "print(df)\n",
    "nlt, lt = df\n",
    "#train, test = sklearn.model_selection.train_test_split(df, test_size=0.1) \n",
    "\n",
    "#todo: to csv\n",
    "nlt.to_csv('data_nlt.csv')\n",
    "lt.to_csv('data_longtail.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model\n",
    "Ensure the gradients in model/wdl.py are frozen (set to False). This trains the model on the non long tail dataset, freezes the lower layers, and saves the model to a checkpoint file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(add_num_times=2, alpha=0.4, anneal_cap=0.2, bert_mask_prob=0.3, best_metric='NDCG@10', block_num=2, cand_num=100, ch=True, context_window=2, dataset_path='data_nlt.csv', decay_step=5, device='cuda', dilations=[1, 4], dropout=0.3, early_stop=True, embedding_size=128, epochs=20, eval=True, factor_num=128, gamma=0.5, hidden_size=128, hidden_size_list=[128, 128], init_method='default', is_mp=False, is_parallel=False, is_pretrain=1, item_min=10, k=20, kd=False, kernel_size=3, l2_emb=0.0, latent_dim=128, lifelong_eval=True, ll_max_itemnum=0, local_rank=None, loss_type='BPR', lr=5e-05, max_len=20, mess_dropout=0.1, metric_ks=[5, 20], model_name='wdl', mtl_task_num=1, negsample_savefolder='./data/neg_data/', negsample_size=99, node_dropout=0.1, num_embedding=1, num_gpu=1, num_groups=4, num_heads=4, num_items=1, num_labels=1, num_ng=4, num_users=1, optimizer='default', pad_token=0, pretrain_path='', prun_rate=0, re_epochs=20, reg_1=0.0, reg_2=0.0, rho=0.5, sample='random', sample_method='high-pop', sample_ratio=0.3, save_path='./checkpoint/', seed=100, source_path='', target_path='', task=-1, task1_out=0, task2_out=0, task3_out=0, task4_out=0, task_name='ctr', task_num=4, temp=7, test_batch_size=4096, test_method='ufo', test_size=0.1, total_anneal_steps=1000, train_batch_size=4096, user_profile='gender', val_batch_size=1024, val_method='ufo', val_size=0.1111, valid_rate=100, weight_decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 313.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linears.0.weight Parameter containing:\n",
      "tensor([[ 3.0481e-05, -9.8775e-05, -2.4937e-04,  ...,  7.6578e-05,\n",
      "         -1.1914e-06, -5.0379e-05],\n",
      "        [ 2.1310e-05, -2.5272e-05, -4.3776e-05,  ..., -5.9525e-05,\n",
      "          1.3884e-04, -1.4521e-04],\n",
      "        [ 6.4192e-05, -3.7306e-05,  7.7259e-05,  ...,  3.3037e-05,\n",
      "          1.2796e-04, -2.2204e-06],\n",
      "        ...,\n",
      "        [ 1.8808e-04,  1.8227e-04,  4.8448e-05,  ..., -1.7503e-04,\n",
      "          5.8444e-05,  9.9155e-05],\n",
      "        [-8.5096e-05, -9.6080e-05,  3.4864e-05,  ..., -3.0924e-05,\n",
      "          5.9960e-06, -2.3068e-05],\n",
      "        [-7.2800e-05, -4.4410e-05,  7.7644e-05,  ...,  1.4750e-04,\n",
      "          4.3578e-05, -1.9624e-04]], device='cuda:0')\n",
      "linears.0.bias Parameter containing:\n",
      "tensor([ 3.4099e-02,  1.6013e-02,  4.2084e-02, -3.1188e-02, -5.4217e-03,\n",
      "         7.0522e-03, -2.8518e-02,  1.2258e-02,  3.4804e-02, -1.8269e-02,\n",
      "        -1.2179e-02,  3.1905e-02,  1.0603e-02, -3.0831e-02,  2.9666e-02,\n",
      "         3.0103e-04, -2.5326e-02,  1.7944e-03,  3.3426e-02, -1.5541e-02,\n",
      "        -9.8133e-03, -2.9122e-03, -3.3789e-02, -4.0380e-02,  3.4784e-02,\n",
      "        -1.0664e-02, -1.6735e-02,  2.5534e-02,  1.5325e-02,  3.8897e-02,\n",
      "         3.2849e-02, -4.3747e-02, -2.6477e-02,  1.9551e-02, -7.4798e-03,\n",
      "         3.8701e-02,  1.8744e-02,  1.5036e-02, -2.4898e-02,  3.7595e-02,\n",
      "         5.3165e-03,  4.1877e-02,  3.4243e-03, -3.0915e-02,  2.0751e-02,\n",
      "         4.5095e-02, -1.4035e-02, -3.6717e-02,  8.4205e-03, -1.7712e-02,\n",
      "         7.8825e-03,  2.4107e-02, -1.8575e-02, -2.4670e-02, -4.3026e-02,\n",
      "         2.3559e-02, -2.3493e-02,  1.9021e-02, -3.2080e-02, -1.1252e-02,\n",
      "        -2.6969e-02,  2.4590e-02,  1.3475e-02, -3.6276e-02,  7.8697e-03,\n",
      "         2.8368e-02,  4.3821e-02, -4.0788e-02, -2.9583e-02,  4.5099e-02,\n",
      "         4.2737e-02, -2.7365e-02, -7.4377e-03,  3.3992e-02,  3.2028e-02,\n",
      "         1.6455e-02, -5.7791e-03, -1.2675e-02, -4.9522e-03, -3.7024e-03,\n",
      "        -3.8460e-02,  5.4436e-03, -2.5513e-02, -1.9106e-02,  4.3536e-02,\n",
      "         3.8911e-02,  3.7562e-02,  2.3893e-02,  2.9798e-02,  6.0933e-04,\n",
      "        -1.6970e-02,  3.8124e-02,  3.2192e-02, -3.7715e-02, -1.6580e-03,\n",
      "        -3.9269e-02,  3.1620e-02,  2.6112e-02,  3.1049e-02, -2.5350e-02,\n",
      "         4.0380e-02,  5.9714e-03,  2.3327e-02,  1.1279e-02,  4.3597e-02,\n",
      "        -4.3553e-02,  3.8949e-02, -6.2949e-03,  3.3358e-02,  1.7272e-02,\n",
      "        -1.6210e-02, -4.3703e-02, -2.2263e-02, -3.9132e-02,  5.0308e-03,\n",
      "        -2.9767e-02, -1.1060e-02,  1.6571e-02, -2.5208e-02, -3.6550e-03,\n",
      "        -2.1863e-02, -2.2101e-02, -6.4065e-03, -1.3606e-02,  5.5354e-03,\n",
      "        -2.5830e-02, -1.4253e-02, -3.2147e-02, -3.5751e-02, -6.7569e-03,\n",
      "        -7.7911e-03,  3.5692e-02, -3.9645e-02, -4.4881e-02, -3.6157e-02,\n",
      "        -1.8190e-02,  1.6732e-02, -8.1636e-03,  1.2203e-02, -3.1882e-02,\n",
      "        -1.9099e-02, -2.5122e-05,  8.5174e-03, -3.7617e-02, -2.9517e-03,\n",
      "         3.5963e-02,  1.4913e-02, -1.4089e-02,  1.1540e-02, -2.5821e-02,\n",
      "        -6.9154e-04,  9.9609e-03,  1.6830e-02, -2.9969e-02,  3.6818e-03,\n",
      "         4.0683e-02, -8.5858e-03,  1.2277e-02, -1.0148e-02,  3.8104e-02,\n",
      "        -1.3316e-02, -5.0645e-03, -1.3909e-02,  3.0572e-02,  1.6007e-03,\n",
      "        -6.4652e-03,  6.7418e-03,  4.2583e-02,  2.2743e-02,  4.5240e-02,\n",
      "         1.2331e-03,  2.0866e-02,  2.4132e-02,  1.1181e-02, -2.5228e-02,\n",
      "         2.0058e-02, -1.4866e-02,  3.9920e-02, -3.9219e-02, -2.1606e-02,\n",
      "        -2.9863e-02, -1.9991e-02,  2.2674e-02,  2.0632e-02, -3.3923e-02,\n",
      "         6.3103e-03,  1.6643e-03, -4.4100e-02, -3.8802e-02,  3.9800e-03,\n",
      "        -8.6725e-03, -3.1050e-02, -3.3152e-02,  1.7180e-02,  2.8960e-02,\n",
      "        -2.9873e-02,  1.2803e-02, -9.5006e-03,  3.5064e-02,  1.6089e-02,\n",
      "         1.1695e-02, -4.2935e-02,  9.6442e-03, -5.6786e-03,  3.8527e-02,\n",
      "         4.0287e-02, -1.5872e-02,  3.9572e-02,  6.1271e-03, -4.4448e-02,\n",
      "         1.7168e-02, -2.1606e-02, -3.0698e-02, -2.1215e-02,  3.4709e-02,\n",
      "         1.0197e-02, -3.3053e-02, -2.7256e-02, -1.8465e-03, -7.6048e-03,\n",
      "        -3.8656e-02, -3.6217e-02,  3.6527e-02, -3.9651e-02, -8.2640e-03,\n",
      "        -8.3463e-03, -2.6519e-02,  3.4013e-02,  2.7508e-02,  4.1754e-02,\n",
      "         2.6684e-02,  1.2111e-02, -2.8994e-02,  4.0894e-02, -4.7543e-03,\n",
      "        -7.6690e-03,  2.0989e-02,  2.5778e-02, -2.9504e-02,  4.3709e-02,\n",
      "         1.6404e-02,  2.3362e-02,  1.0046e-02, -6.1081e-03,  3.4868e-02,\n",
      "        -2.9438e-02,  2.5915e-02, -1.9926e-02,  6.1201e-04,  2.1848e-02,\n",
      "         2.9430e-02,  2.9912e-02, -1.4399e-02,  3.1366e-02, -3.7819e-02,\n",
      "        -1.5438e-02], device='cuda:0')\n",
      "linears.1.weight Parameter containing:\n",
      "tensor([[ 8.7224e-05, -9.7334e-06, -1.3084e-04,  ..., -6.4222e-05,\n",
      "          7.5662e-05, -5.7546e-05],\n",
      "        [ 6.9369e-05,  1.0869e-04, -4.5337e-05,  ..., -1.8588e-05,\n",
      "          2.7973e-04,  7.7593e-05],\n",
      "        [-8.5238e-05,  1.2190e-04,  1.7333e-04,  ...,  6.5970e-05,\n",
      "         -6.7625e-05, -2.3012e-04],\n",
      "        ...,\n",
      "        [ 8.2678e-05, -9.9063e-05,  1.8416e-04,  ..., -1.2469e-06,\n",
      "          4.1461e-05,  1.4703e-04],\n",
      "        [ 3.1471e-05, -2.9933e-05, -6.5484e-06,  ..., -1.1004e-04,\n",
      "          9.0339e-05, -8.9445e-05],\n",
      "        [-6.0561e-05,  1.6003e-04, -1.0416e-04,  ..., -7.5494e-05,\n",
      "          9.9083e-05,  9.4307e-05]], device='cuda:0')\n",
      "linears.1.bias Parameter containing:\n",
      "tensor([ 3.1751e-02,  9.3334e-03,  3.4058e-02, -1.7448e-02, -4.9662e-02,\n",
      "         5.5032e-02,  1.1687e-02,  1.6924e-02,  3.5303e-02, -4.1738e-02,\n",
      "         1.0509e-02, -1.5614e-02, -8.1336e-03,  3.9746e-02,  3.7165e-02,\n",
      "         1.6309e-02,  5.5151e-02,  3.8221e-02,  5.7698e-02, -1.9778e-02,\n",
      "         3.9026e-02,  7.0780e-03,  3.7971e-03, -3.8388e-02, -1.7775e-02,\n",
      "        -4.1656e-02, -2.6633e-02, -1.5827e-02,  2.7478e-02,  3.3741e-02,\n",
      "         6.7644e-04, -3.1786e-02, -4.5464e-02,  4.0837e-02, -3.8371e-02,\n",
      "        -2.4363e-02, -2.0036e-02, -4.1097e-02,  2.8293e-02, -3.4853e-02,\n",
      "         5.5120e-02,  5.0272e-03,  5.9468e-02,  3.1762e-03, -6.1757e-02,\n",
      "        -4.5425e-02,  2.3514e-03,  2.6214e-02,  3.2724e-02,  2.5680e-02,\n",
      "         1.1239e-03, -4.6957e-02,  2.1108e-02, -2.4718e-02,  7.9269e-03,\n",
      "         1.1659e-02,  6.0462e-02, -5.2332e-02,  4.9902e-03,  2.6872e-02,\n",
      "        -1.4475e-02, -2.3013e-02,  2.3077e-02,  2.8271e-02,  1.8504e-02,\n",
      "        -9.6605e-03,  3.6031e-02,  2.2153e-02, -1.0440e-02,  5.2307e-03,\n",
      "         7.7292e-03, -2.7320e-02,  3.8549e-02, -5.4188e-02,  1.8973e-02,\n",
      "         5.6133e-02, -3.4421e-02, -1.5535e-02, -1.8331e-02, -3.8641e-02,\n",
      "         1.9197e-02, -6.1741e-02, -1.7806e-02,  4.5184e-02, -4.4362e-02,\n",
      "         4.4469e-02,  3.6954e-02, -3.7001e-02, -6.9015e-03,  1.2781e-03,\n",
      "         3.8032e-02,  3.1929e-02,  1.0500e-02, -5.6813e-02,  4.0135e-02,\n",
      "        -5.0140e-02,  5.2820e-02, -5.1961e-02, -3.0458e-02, -3.9164e-02,\n",
      "         1.2383e-02,  2.0753e-02, -4.2344e-02,  5.9585e-02,  1.3605e-02,\n",
      "        -6.2308e-02, -2.2940e-02, -1.9601e-02,  2.4964e-02,  3.6413e-02,\n",
      "         1.3182e-02,  1.3675e-02, -1.2524e-02,  3.1245e-02, -2.1094e-02,\n",
      "        -1.4013e-02, -2.5570e-02,  4.1388e-02, -3.4580e-02, -5.2949e-02,\n",
      "         4.8209e-02,  4.0119e-02, -1.5957e-02,  1.9748e-02,  3.4347e-02,\n",
      "         4.1603e-02, -2.4075e-02, -3.1640e-02, -2.1246e-02, -4.5460e-02,\n",
      "         5.0137e-02,  5.5106e-02, -5.7761e-02, -3.4611e-03, -3.7300e-02,\n",
      "         1.8315e-02,  2.8827e-02, -1.6263e-02,  4.4826e-02,  3.6505e-02,\n",
      "         4.9502e-02, -3.7722e-02, -1.6845e-02, -5.7017e-02,  8.8645e-03,\n",
      "        -1.7503e-02,  4.7391e-02, -2.6807e-02, -5.8235e-02, -3.1037e-02,\n",
      "         3.2991e-05,  4.3162e-02, -2.9889e-03,  5.4037e-02, -5.9767e-02,\n",
      "         1.7499e-02,  5.9039e-02,  4.2356e-02, -2.8874e-02,  2.7525e-02,\n",
      "         5.1586e-02, -4.8137e-03,  2.5024e-02,  4.9806e-02,  9.2643e-03,\n",
      "         1.8218e-02,  2.0618e-02, -2.7974e-02,  3.3332e-02,  2.2836e-02,\n",
      "        -2.7181e-02,  4.6598e-03, -2.4350e-02, -2.0608e-02,  5.4018e-03,\n",
      "         3.1257e-02, -2.4191e-02,  4.4558e-02, -3.9651e-02,  2.7615e-02,\n",
      "         5.6266e-02, -4.3389e-02, -5.6540e-02, -2.8329e-02,  9.6427e-03,\n",
      "         5.7514e-02,  3.7334e-02,  1.9366e-02, -5.5934e-03, -3.2918e-02,\n",
      "        -4.8980e-02, -4.7522e-02, -3.8751e-02,  2.3708e-02, -2.7891e-02,\n",
      "         5.8843e-02, -4.4955e-02, -4.6388e-02,  6.0771e-04,  5.4404e-02,\n",
      "         6.1048e-02,  3.9042e-02,  4.7542e-02,  4.9710e-02,  7.2495e-03,\n",
      "        -4.4756e-02,  3.7598e-02,  4.5811e-02, -5.1035e-02,  1.5102e-02,\n",
      "        -4.0570e-02, -2.9532e-02,  3.7378e-02,  3.7851e-02,  2.5297e-02,\n",
      "        -2.8641e-02,  2.6439e-02,  1.8206e-02, -2.2701e-02,  1.3013e-02,\n",
      "         2.3416e-02,  2.2319e-03, -3.7377e-02, -6.1223e-02, -3.8997e-02,\n",
      "        -8.1843e-03,  5.2350e-02, -6.1182e-02, -4.3835e-02, -1.1036e-02,\n",
      "         5.8630e-02,  1.9074e-02,  4.9446e-02, -1.2911e-03, -2.8370e-02,\n",
      "        -2.1505e-02, -1.5293e-02, -1.6776e-02, -2.8902e-02, -3.3726e-02,\n",
      "         5.4011e-02,  5.9973e-03,  3.5321e-02,  5.5761e-02, -5.6541e-02,\n",
      "         1.1472e-02,  1.1353e-02,  6.1410e-02,  1.1688e-02,  1.8313e-02,\n",
      "        -1.9346e-02, -3.7192e-02, -2.0884e-02, -1.4084e-02, -5.2642e-02,\n",
      "        -1.0575e-02], device='cuda:0')\n",
      "cuda\n",
      "Train on 27290 samples, validate on 3411 samples, 7 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "0s - loss:  0.6920 - auc:  0.5979 - acc:  0.6663 - val_auc:  0.6616 - val_acc:  0.6614\n",
      "Epoch 2/20\n",
      "0s - loss:  0.6908 - auc:  0.7400 - acc:  0.6663 - val_auc:  0.6714 - val_acc:  0.6614\n",
      "Epoch 3/20\n",
      "0s - loss:  0.6898 - auc:  0.7505 - acc:  0.6663 - val_auc:  0.6736 - val_acc:  0.6614\n",
      "Epoch 4/20\n",
      "0s - loss:  0.6887 - auc:  0.7537 - acc:  0.6663 - val_auc:  0.6744 - val_acc:  0.6614\n",
      "Epoch 5/20\n",
      "0s - loss:  0.6876 - auc:  0.7551 - acc:  0.6663 - val_auc:  0.6747 - val_acc:  0.6614\n",
      "Epoch 6/20\n",
      "0s - loss:  0.6866 - auc:  0.7560 - acc:  0.6663 - val_auc:  0.6750 - val_acc:  0.6614\n",
      "Epoch 7/20\n",
      "0s - loss:  0.6855 - auc:  0.7566 - acc:  0.6663 - val_auc:  0.6751 - val_acc:  0.6614\n",
      "Epoch 8/20\n",
      "0s - loss:  0.6845 - auc:  0.7571 - acc:  0.6664 - val_auc:  0.6752 - val_acc:  0.6614\n",
      "Epoch 9/20\n",
      "0s - loss:  0.6834 - auc:  0.7574 - acc:  0.6664 - val_auc:  0.6753 - val_acc:  0.6614\n",
      "Epoch 10/20\n",
      "0s - loss:  0.6824 - auc:  0.7578 - acc:  0.6664 - val_auc:  0.6754 - val_acc:  0.6614\n",
      "Epoch 11/20\n",
      "0s - loss:  0.6814 - auc:  0.7580 - acc:  0.6665 - val_auc:  0.6755 - val_acc:  0.6614\n",
      "Epoch 12/20\n",
      "0s - loss:  0.6804 - auc:  0.7583 - acc:  0.6665 - val_auc:  0.6756 - val_acc:  0.6614\n",
      "Epoch 13/20\n",
      "0s - loss:  0.6794 - auc:  0.7586 - acc:  0.6667 - val_auc:  0.6757 - val_acc:  0.6614\n",
      "Epoch 14/20\n",
      "0s - loss:  0.6784 - auc:  0.7588 - acc:  0.6670 - val_auc:  0.6758 - val_acc:  0.6611\n",
      "Epoch 15/20\n",
      "0s - loss:  0.6774 - auc:  0.7590 - acc:  0.6671 - val_auc:  0.6758 - val_acc:  0.6611\n",
      "Epoch 16/20\n",
      "0s - loss:  0.6765 - auc:  0.7593 - acc:  0.6671 - val_auc:  0.6760 - val_acc:  0.6614\n",
      "Epoch 17/20\n",
      "0s - loss:  0.6755 - auc:  0.7595 - acc:  0.6672 - val_auc:  0.6760 - val_acc:  0.6614\n",
      "Epoch 18/20\n",
      "0s - loss:  0.6745 - auc:  0.7597 - acc:  0.6672 - val_auc:  0.6761 - val_acc:  0.6614\n",
      "Epoch 19/20\n",
      "0s - loss:  0.6736 - auc:  0.7599 - acc:  0.6673 - val_auc:  0.6763 - val_acc:  0.6614\n",
      "Epoch 20/20\n",
      "0s - loss:  0.6727 - auc:  0.7601 - acc:  0.6675 - val_auc:  0.6764 - val_acc:  0.6614\n",
      "test LogLoss 0.6745\n",
      "test AUC 0.6802\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'BaseModel._get_metrics.<locals>.<lambda>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Final Project/2022-NIPS-Tenrec/main.py:501\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    496\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave({\n\u001b[1;32m    497\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: best_model\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: optimizer\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m    499\u001b[0m         }, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_best_nlt.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m#torch.save(best_model.state_dict(), \"model_best_nlt.ckpt\") \u001b[39;00m\n\u001b[0;32m--> 501\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_best_nlt.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mtask_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mctr2\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdin\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdien\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:379\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 379\u001b[0m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    381\u001b[0m _legacy_save(obj, opened_file, pickle_module, pickle_protocol)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:484\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    482\u001b[0m pickler \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mPickler(data_buf, protocol\u001b[38;5;241m=\u001b[39mpickle_protocol)\n\u001b[1;32m    483\u001b[0m pickler\u001b[38;5;241m.\u001b[39mpersistent_id \u001b[38;5;241m=\u001b[39m persistent_id\n\u001b[0;32m--> 484\u001b[0m \u001b[43mpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m data_value \u001b[38;5;241m=\u001b[39m data_buf\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    486\u001b[0m zip_file\u001b[38;5;241m.\u001b[39mwrite_record(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, data_value, \u001b[38;5;28mlen\u001b[39m(data_value))\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'BaseModel._get_metrics.<locals>.<lambda>'"
     ]
    }
   ],
   "source": [
    "%run -i main.py --task_name=ctr --seed=100 --model_name=wdl --dataset_path=data_nlt.csv --train_batch_size=4096 --test_batch_size=4096 --epochs=20 --lr=0.00005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish training model\n",
    "Ensure the gradients in model/wdl.py are set to True. This finishes training the model on the long tail items only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(add_num_times=2, alpha=0.4, anneal_cap=0.2, bert_mask_prob=0.3, best_metric='NDCG@10', block_num=2, cand_num=100, ch=True, context_window=2, dataset_path='data_longtail.csv', decay_step=5, device='cuda', dilations=[1, 4], dropout=0.3, early_stop=True, embedding_size=128, epochs=20, eval=True, factor_num=128, gamma=0.5, hidden_size=128, hidden_size_list=[128, 128], init_method='default', is_mp=False, is_parallel=False, is_pretrain=1, item_min=10, k=20, kd=False, kernel_size=3, l2_emb=0.0, latent_dim=128, lifelong_eval=True, ll_max_itemnum=0, local_rank=None, loss_type='BPR', lr=5e-05, max_len=20, mess_dropout=0.1, metric_ks=[5, 20], model_name='wdl', mtl_task_num=1, negsample_savefolder='./data/neg_data/', negsample_size=99, node_dropout=0.1, num_embedding=1, num_gpu=1, num_groups=4, num_heads=4, num_items=1, num_labels=1, num_ng=4, num_users=1, optimizer='default', pad_token=0, pretrain_path='', prun_rate=0, re_epochs=20, reg_1=0.0, reg_2=0.0, rho=0.5, sample='random', sample_method='high-pop', sample_ratio=0.3, save_path='./checkpoint/', seed=100, source_path='', target_path='', task=-1, task1_out=0, task2_out=0, task3_out=0, task4_out=0, task_name='ctr2', task_num=4, temp=7, test_batch_size=4096, test_method='ufo', test_size=0.1, total_anneal_steps=1000, train_batch_size=4096, user_profile='gender', val_batch_size=1024, val_method='ufo', val_size=0.1111, valid_rate=100, weight_decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 148.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linears.0.weight Parameter containing:\n",
      "tensor([[-9.5275e-05, -1.4188e-04, -5.6926e-05,  ...,  5.6338e-05,\n",
      "         -1.9277e-04,  1.3893e-04],\n",
      "        [ 7.1253e-05,  4.2341e-05, -7.8404e-05,  ..., -8.5493e-05,\n",
      "          1.3951e-05,  1.1881e-04],\n",
      "        [ 8.0746e-05,  9.8401e-05, -9.6685e-05,  ...,  1.0969e-04,\n",
      "         -9.6909e-05, -8.1658e-05],\n",
      "        ...,\n",
      "        [ 9.0726e-05, -1.3722e-04,  1.1560e-06,  ...,  8.7109e-05,\n",
      "          8.2887e-05,  4.2041e-05],\n",
      "        [ 9.1943e-05, -6.3253e-05, -8.4764e-05,  ...,  1.0781e-04,\n",
      "          7.3561e-05, -5.0638e-05],\n",
      "        [-1.5677e-04,  1.8946e-04, -1.1029e-04,  ..., -3.7671e-05,\n",
      "         -1.0408e-04,  5.5160e-05]], device='cuda:0')\n",
      "linears.0.bias Parameter containing:\n",
      "tensor([-3.3047e-02, -1.7115e-02,  9.7987e-03, -1.2895e-02, -3.9120e-03,\n",
      "        -2.4593e-02, -7.5216e-04,  4.1958e-02,  3.6821e-02,  2.1513e-03,\n",
      "        -4.2643e-02,  6.4565e-05,  4.4919e-02,  9.1858e-03, -4.4060e-02,\n",
      "        -1.9113e-02, -1.4512e-02,  2.6869e-02,  2.5116e-02,  1.8192e-02,\n",
      "         8.9294e-03, -4.3653e-02,  3.7439e-02, -2.1388e-02, -1.2095e-02,\n",
      "         3.1630e-02,  1.0650e-02,  1.2041e-02, -2.3031e-02,  1.2103e-02,\n",
      "         2.6604e-02, -2.2843e-02,  7.2055e-03,  3.9646e-02, -3.4420e-02,\n",
      "         1.6802e-02, -2.6809e-02,  6.4278e-03, -3.0944e-02, -3.0838e-02,\n",
      "        -4.4438e-02, -3.9718e-02, -3.1609e-02, -1.4584e-02, -2.1214e-02,\n",
      "        -7.2826e-03, -1.7940e-02, -1.7362e-02, -2.4726e-02, -2.0240e-03,\n",
      "        -1.5088e-02, -2.0940e-03,  1.0627e-02, -3.2141e-02, -6.4697e-03,\n",
      "         3.1250e-02,  1.0679e-02, -2.4428e-02,  1.1126e-02,  3.2408e-02,\n",
      "         1.0107e-02, -2.9522e-02,  3.8700e-02, -8.2300e-03, -4.4413e-02,\n",
      "         8.5406e-03,  3.3888e-02, -2.6575e-03,  2.9950e-02,  2.1326e-03,\n",
      "         2.7259e-02, -4.3764e-02, -3.4718e-02, -9.4576e-03, -4.8776e-03,\n",
      "        -2.9722e-02, -1.0807e-02, -1.0501e-02, -2.3909e-02,  2.8637e-02,\n",
      "        -9.5728e-03,  1.6598e-03,  4.8402e-03, -3.5875e-02, -2.3722e-02,\n",
      "        -4.5480e-02,  1.4948e-02,  5.4147e-03, -3.9936e-03, -2.0955e-02,\n",
      "         3.2497e-02,  3.7987e-02,  1.5501e-02,  4.3990e-02, -2.5780e-02,\n",
      "         4.0413e-02,  3.5304e-02, -9.1623e-03, -4.4318e-02, -1.2070e-02,\n",
      "         4.8076e-03, -4.2808e-03, -6.5539e-03, -2.2930e-02, -4.0209e-02,\n",
      "        -4.1978e-02,  1.6773e-03, -3.8146e-02, -1.7373e-02, -4.0245e-02,\n",
      "         3.6032e-02,  1.4210e-02, -2.8438e-02,  7.7821e-03,  3.1481e-02,\n",
      "        -1.1411e-02,  3.4572e-02, -3.0827e-02,  3.0410e-02,  2.4531e-02,\n",
      "         4.1981e-02, -1.7826e-02, -1.7444e-02, -1.8552e-02,  3.7830e-02,\n",
      "         5.2289e-04,  2.1618e-02,  1.6597e-02,  2.8903e-02,  3.2560e-02,\n",
      "        -7.2601e-05, -2.5474e-02,  3.6435e-02, -1.5289e-02, -3.4957e-03,\n",
      "        -2.4335e-02,  4.3100e-02, -4.5168e-02,  2.9885e-02, -1.1704e-02,\n",
      "        -4.6098e-03, -1.8107e-02, -3.9688e-02, -3.9070e-02,  1.1247e-02,\n",
      "        -1.7336e-02,  1.2259e-02,  1.2434e-02, -8.3446e-03,  1.5124e-02,\n",
      "         8.4156e-04, -3.8014e-02,  4.3848e-03,  3.3899e-02,  1.7389e-02,\n",
      "        -2.6827e-02,  1.4333e-02,  2.7037e-02, -7.9105e-03,  7.3451e-03,\n",
      "         1.6949e-02,  3.3195e-02,  3.0732e-02,  1.8611e-02, -6.7338e-03,\n",
      "        -1.7799e-02,  1.7117e-02,  1.4609e-02, -3.8655e-02, -1.0509e-02,\n",
      "         2.9511e-02, -4.4766e-02, -3.3160e-02,  2.2464e-03, -1.3142e-02,\n",
      "        -3.3742e-02,  1.9777e-02,  3.3554e-02,  1.2235e-02, -3.1036e-02,\n",
      "         2.1777e-02,  3.4175e-02, -1.0473e-02,  2.9272e-02,  3.8703e-02,\n",
      "         2.3083e-02, -3.3456e-03,  3.3417e-02,  2.9805e-02,  1.1247e-02,\n",
      "        -2.6132e-03,  4.2117e-02, -2.4785e-04,  3.3940e-02,  1.0073e-02,\n",
      "         2.3657e-02,  9.9150e-03,  2.6663e-02,  3.3784e-02, -2.7503e-02,\n",
      "        -3.3227e-02,  1.6519e-02, -9.0444e-03,  3.2834e-02,  3.0627e-02,\n",
      "        -5.6270e-03,  1.2910e-03, -8.4653e-04,  9.7688e-03, -3.2358e-03,\n",
      "        -4.3836e-02, -1.0575e-02, -6.1370e-03,  1.9592e-02,  4.0439e-02,\n",
      "         2.3995e-03, -2.4704e-02,  1.6934e-02, -1.2813e-02, -2.7912e-02,\n",
      "        -2.9764e-02, -2.3183e-02, -4.2265e-02, -4.5098e-02, -4.6211e-03,\n",
      "        -5.6949e-03,  9.9731e-05,  3.3816e-02,  3.4272e-02, -4.1214e-02,\n",
      "        -1.2269e-03, -3.5785e-02,  3.9173e-03, -3.0113e-02,  6.9666e-03,\n",
      "        -3.0427e-02, -3.5075e-02,  3.6754e-02,  2.8614e-02,  8.1065e-03,\n",
      "         1.8165e-02, -3.2778e-02,  1.9951e-02, -2.4551e-02, -1.5436e-03,\n",
      "        -4.5626e-02,  2.6421e-02, -2.4713e-02, -3.4859e-02,  3.8025e-02,\n",
      "        -2.1257e-02,  3.8150e-02, -1.7733e-02, -4.8938e-03,  3.2842e-02,\n",
      "        -3.8526e-02], device='cuda:0')\n",
      "linears.1.weight Parameter containing:\n",
      "tensor([[-1.5811e-04,  1.1733e-04, -2.5334e-05,  ...,  4.8095e-05,\n",
      "          1.4939e-04,  8.8141e-05],\n",
      "        [-2.0947e-05, -8.9592e-05,  8.9110e-05,  ...,  1.4993e-04,\n",
      "         -7.2871e-05,  3.6707e-06],\n",
      "        [ 1.2792e-04, -1.5045e-06,  2.1890e-05,  ..., -1.1315e-04,\n",
      "          5.0803e-05, -2.4184e-05],\n",
      "        ...,\n",
      "        [-9.1280e-05, -3.4315e-05,  6.3399e-05,  ..., -1.4158e-04,\n",
      "         -3.4849e-05, -1.3053e-05],\n",
      "        [ 9.2404e-05, -2.7074e-05,  3.4983e-05,  ...,  5.4259e-05,\n",
      "          3.3673e-05,  6.4346e-05],\n",
      "        [-2.8672e-04,  3.7076e-05, -5.0756e-05,  ..., -1.5963e-04,\n",
      "         -6.8535e-05,  8.9841e-05]], device='cuda:0')\n",
      "linears.1.bias Parameter containing:\n",
      "tensor([ 0.0463,  0.0293,  0.0464, -0.0278,  0.0563,  0.0068,  0.0305,  0.0540,\n",
      "        -0.0475,  0.0077, -0.0184, -0.0515, -0.0427,  0.0371,  0.0336, -0.0450,\n",
      "        -0.0470,  0.0107, -0.0183,  0.0483, -0.0415,  0.0562,  0.0598, -0.0349,\n",
      "         0.0064, -0.0184, -0.0491,  0.0266,  0.0334,  0.0519,  0.0247, -0.0191,\n",
      "         0.0568,  0.0200,  0.0612, -0.0501, -0.0012, -0.0588,  0.0383, -0.0583,\n",
      "        -0.0467,  0.0062, -0.0521,  0.0301, -0.0460,  0.0132,  0.0051, -0.0165,\n",
      "        -0.0038,  0.0606, -0.0385, -0.0195, -0.0194, -0.0094, -0.0012, -0.0160,\n",
      "        -0.0497,  0.0620,  0.0524, -0.0161,  0.0334,  0.0147,  0.0116, -0.0392,\n",
      "        -0.0409, -0.0274, -0.0313, -0.0397,  0.0463, -0.0277,  0.0234,  0.0609,\n",
      "         0.0185,  0.0610,  0.0297, -0.0523,  0.0326,  0.0573, -0.0557, -0.0079,\n",
      "         0.0109, -0.0509,  0.0394,  0.0370, -0.0206,  0.0302,  0.0133,  0.0563,\n",
      "        -0.0424, -0.0135, -0.0159,  0.0296, -0.0358, -0.0613,  0.0370, -0.0375,\n",
      "        -0.0556, -0.0154,  0.0025,  0.0461, -0.0346, -0.0400,  0.0400,  0.0126,\n",
      "        -0.0154, -0.0067,  0.0170, -0.0581, -0.0134,  0.0576,  0.0543, -0.0449,\n",
      "        -0.0057,  0.0594,  0.0024, -0.0230,  0.0193, -0.0376,  0.0412,  0.0240,\n",
      "        -0.0432, -0.0455, -0.0070, -0.0019, -0.0187,  0.0367,  0.0060,  0.0254,\n",
      "         0.0178,  0.0139,  0.0433,  0.0246, -0.0235, -0.0270, -0.0578,  0.0022,\n",
      "        -0.0373,  0.0477,  0.0188,  0.0478,  0.0018,  0.0469, -0.0412, -0.0419,\n",
      "        -0.0458,  0.0460, -0.0345, -0.0602, -0.0526,  0.0523, -0.0026, -0.0256,\n",
      "         0.0058,  0.0608,  0.0335,  0.0286, -0.0406,  0.0048,  0.0436, -0.0126,\n",
      "        -0.0071, -0.0482,  0.0477,  0.0337,  0.0120,  0.0100, -0.0331,  0.0479,\n",
      "         0.0521, -0.0206,  0.0085, -0.0015, -0.0042, -0.0216,  0.0300, -0.0514,\n",
      "        -0.0227,  0.0031, -0.0016,  0.0142,  0.0155,  0.0535, -0.0218, -0.0243,\n",
      "         0.0067,  0.0019,  0.0324, -0.0199, -0.0495, -0.0042, -0.0126,  0.0232,\n",
      "        -0.0009, -0.0340, -0.0519,  0.0154,  0.0610, -0.0151, -0.0124,  0.0018,\n",
      "        -0.0445, -0.0398, -0.0408,  0.0389, -0.0041, -0.0268, -0.0012, -0.0215,\n",
      "         0.0509, -0.0143, -0.0618, -0.0529, -0.0509,  0.0019, -0.0029,  0.0266,\n",
      "        -0.0409, -0.0501,  0.0197, -0.0597, -0.0207,  0.0018, -0.0277, -0.0585,\n",
      "         0.0556, -0.0333, -0.0452, -0.0138,  0.0251,  0.0582,  0.0574,  0.0623,\n",
      "        -0.0416, -0.0178, -0.0496,  0.0622, -0.0092, -0.0527, -0.0229, -0.0286,\n",
      "        -0.0410,  0.0007,  0.0217,  0.0210, -0.0510,  0.0206,  0.0563,  0.0603,\n",
      "        -0.0372,  0.0313, -0.0496, -0.0272,  0.0016,  0.0270, -0.0282,  0.0331],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'load_state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Final Project/2022-NIPS-Tenrec/main.py:521\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'load_state_dict'"
     ]
    }
   ],
   "source": [
    "%run -i main.py --task_name=ctr2 --seed=100 --model_name=wdl --dataset_path=data_longtail.csv --train_batch_size=4096 --test_batch_size=4096 --epochs=20 --lr=0.00005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctr_data_1M.csv\n"
     ]
    }
   ],
   "source": [
    "!tar chvfz notebook.tar.gz *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "%run -i main.py --task_name=ctr --seed=100 --model_name=wdl --dataset_path=ctr_data_1M.csv --train_batch_size=4096 --test_batch_size=4096 --epochs=20 --lr=0.00005\n",
    "\n",
    "            for name, para in self.dnn.named_parameters():\n",
    "                print(name, para)\n",
    "                para.requires_grad = False\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
